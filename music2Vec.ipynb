import urllib.request
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
import re
from PIL import Image
from io import BytesIO
from nltk.tokenize import RegexpTokenizer
import nltk
from gensim.models import Word2Vec
from gensim.models import KeyedVectors
from nltk.corpus import stopwords
from sklearn.metrics.pairwise import cosine_similarity
import nltk

nltk.download([
     "names",
     "stopwords",
     "state_union",
    "twitter_samples",
     "movie_reviews",
     "averaged_perceptron_tagger",
     "vader_lexicon",
     "punkt",
 ])
 
from nltk.sentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()
urllib.request.urlretrieve("https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz", \
                           filename="GoogleNews-vectors-negative300.bin.gz")   

def _removeNonAscii(s):
    return "".join(i for i in s if  ord(i)<128)

def make_lower_case(text):
    return text.lower()

def remove_stop_words(text):
    text = text.split()
    stops = set(stopwords.words("english"))
    text = [w for w in text if not w in stops]
    text = " ".join(text)
    return text

def remove_html(text):
    html_pattern = re.compile('<.*?>')
    return html_pattern.sub(r'', text)

def remove_punctuation(text):
    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')
    text = tokenizer.tokenize(text)
    text = " ".join(text)
    return text

def vectors(music_list):
    music_embedding_list = []

    # 각 노래 대해서
    for line in music_list:
        music2vec = None
        count = 0
        for word in line:
            if word in word2vec_model.wv.vocab:
                count += 1
                # 해당 노래에 있는 모든 단어들의 벡터값을 더한다.
                if music2vec is None:
                    music2vec = word2vec_model[word]
                else:
                    music2vec = music2vec + word2vec_model[word]

        if music2vec is not None:
            # 단어 벡터를 모두 더한 벡터의 값을 가사 길이로 나눠준다.
            music2vec = music2vec / count
            music_embedding_list.append(music2vec)

    # 각 가사에 대한 가사 벡터 리스트를 리턴
    return music_embedding_list

def similarMatching(title, df, cosine_similarities):
    musics = df[['track_name', 'release_date']]
    df=df.append({'track_name' : title , 'lyrics' : title, 'release_date' : '0000'} , ignore_index=True)

    # 노래의 가사를 입력하면 해당 노래를 넣고 idx에 저장.
    indices = pd.Series(df.index, index = df['track_name']).drop_duplicates() 
    idx = indices[title]

    # 입력된 노래와 가사(embedding)가 유사한 노래 5개 선정.
    sim_scores = list(enumerate(cosine_similarities[idx]))

    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)

    sim_scores = sim_scores[1:6]

    # 가장 유사한 노래 5곡의 인덱스
    book_indices = [i[0] for i in sim_scores]

    # 전체 데이터프레임에서 해당 인덱스의 행만 추출. 5개의 행을 가진다.
    recommend = musics.iloc[book_indices].reset_index(drop=True)
    print("these songs are similar")
    print("--------------------------------------------------------------------------")
    print(recommend)
    print("--------------------------------------------------------------------------")
    # 데이터프레임으로부터 순차적으로 제목과 년도
    answer=recommend['release_date'].values.tolist()
    return answer

def bigdataProject(lyric, word2vec_model, corpus):
  #업데이트한 값으로 데이타 프레임 생성(index 0)
  
  for words in df['cleaned']:
    corpus.append(words.split())
  corpus.append(inputMusic)

  
  word2vec_model.build_vocab(corpus)
  word2vec_model.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)
  word2vec_model.train(corpus, total_examples = word2vec_model.corpus_count, epochs = 15)

def bigdataProject2(lyric, corpus, word2vec_model, df):
  print(corpus[0:3])
  document_embedding_list = vectors(corpus)
  print("--------------------------------------------------------------------------")
  print('가사 벡터의 수 :',len(document_embedding_list))
  print("--------------------------------------------------------------------------")
  cosine_similarities = cosine_similarity(document_embedding_list, document_embedding_list)
  return similarMatching(lyric, df, cosine_similarities)

df = pd.read_csv("/content/drive/MyDrive/BigData_csv/tcc_ceds_music 2.csv")
df['cleaned'] = df['lyrics'].apply(_removeNonAscii)
df['cleaned'] = df.cleaned.apply(make_lower_case)
df['cleaned'] = df.cleaned.apply(remove_stop_words)
df['cleaned'] = df.cleaned.apply(remove_punctuation)
df['cleaned'] = df.cleaned.apply(remove_html)
df['cleaned'].replace('', np.nan, inplace=True)
df = df[df['cleaned'].notna()]


word2vec_model = Word2Vec(size = 300, window=5, min_count = 2, workers = -1)
parsedLyrics = []
print("==========================================================================")
inputLyric = input('가사를 입력하세요: ')     # 사용자의 입력을 변수에 저장
inputMusic=inputLyric.split(' ')
bigdataProject(inputMusic, word2vec_model, parsedLyrics)
years=bigdataProject2(inputLyric, parsedLyrics, word2vec_model, df)

sia = SentimentIntensityAnalyzer()
print("==========================================================================")

print("감정 분석 결과 : ", sia.polarity_scores(inputLyric))
print("--------------------------------------------------------------------------")

print("관련있는 년도 : ",years)
print("==========================================================================")
